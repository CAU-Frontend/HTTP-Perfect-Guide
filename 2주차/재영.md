# ⏰ HTTP 완벽 가이드 4장(커넥션) ⏰

HTTP 애플리케이션을 개발한다면 HTTP 커넥션과 그것이 어떻게 사용되는지에 대해 알아야 함

- HTTP는 어떻게 TCP 커넥션을 사용하는지
- TCP 커넥션의 지연, 병목, 막힘
- 병렬 커넥션, keep-alive 커넥션, 커넥션 파이프라인을 활용한 HTTP의 최적화
- 커넥션 관리를 위해 따라야 할 규칙

## TCP 커넥션

모든 HTTP 통신은 **패킷 교환 네트워크 프로토콜들의 계층화된 집합**인 TCP/IP를 통해 이루어짐
클라이언트와 서버는 어디서든 TCP/IP 통신을 맺을 수 있음 => 통신을 맺어 메시지 송수신 가능

### TCP 커넥션 과정

http://www.naver.com:80/tools.html 입력

1. naver.com이라는 호스트 명 추출
2. 브라우저가 이 호스트 명에 대한 IP 주소 탐색
3. 브라우저가 포트 번호 추출
   // URL을 통한 IP와 포트 번호 추출

4. 브라우저가 IP와 포트 번호로 TCP 커넥션 생성
   // TCP 커넥션

5. 브라우저가 서버로 HTTP GET 메시지 전송
6. 브라우저가 서버에서 온 HTTP 응답 파싱
7. 브라우저가 커넥션 종료
   // TCP를 통한 요청과 응답

TCP 커넥션을 통해 전송하는 바이트는 순서에 맞게 정확히 전달

### TCP/IP

TCP는 IP 패킷이라고 불리는 작은 조각을 이용해 데이터를 전송
TCP는 세그먼트라는 단위로 데이터 스트림을 잘게 나누고, IP 패킷이라고 불리는 봉투에 담아서 데이터를 전달
이 과정은 TCP/IP 소프트웨어에 의해 처리되며 그 과정은 개발자에게 보이지 않음

**IP 패킷 내부**

IP 패킷 헤더

- 발신지, 목적지 IP, 크기, 기타 플래그

TCP 세그먼트 헤더

- TCP 포트 넘버, TCP 제어 플래그, 데이터의 순서와 무결성 검사를 위한 값

TCP 데이터(조각)

### TCP 커넥션 유지

TCP 커넥션은 네 가지 값으로 식별

1. 발신지 IP
2. 발신지 포트
3. 수신자 IP
4. 수신자 포트

위 4가지 값으로 유일한 커넥션 생성 => 커넥션 끼리 위 4가지 값이 다 같을 수 없음 => 4개의 값의 해당하는 커넥션을 생성하여 유지하는 것

### TCP 소켓 프로그래밍

소켓은 HTTP 개발자에게 TCP와 IP 세부사항을 숨김

소켓을 사용하면 TCP 종단 데이터 구조를 생성, 원격 서버의 데이터 구조를 연결하여 데이터 스트림을 R/W 가능

### TCP 성능

HTTP 트랜잭션 지연 이유

1. 최근에 접속한 URL가 아니라면 호스트 명을 IP 주소로 변환하는데 오래 걸림
2. HTTP 트랜잭션이 많이 생기면 커넥션 설정 소요 시간이 크게 증가
3. 요청 처리에 시간 소요
4. 응답 전송 시간 소요

성능 관련 중요 요소

1. TCP 커넥션 헨드셰이크 설정

- SYN과 SYN-ACK를 위한 시간 소요

2. TCP의 SLOW START

- TCP 커넥션은 생성된 초반에는 최대 속도를 제한 => 이후 성공적으로 전송됨에 따라서 속도 제한 증가(튜닝)
- 속도 제한 === 한 번의 보낼 수 있는 패킷 수 제한

3. 확인 응답 지연 알고리즘

- TCP는 성공적인 데이터 전송을 보장하기 위해 확인 체계를 가짐
- 데이터를 온전히 받으면 확인응답 패킷을 송신자에게 반환해야 함
- 크기가 작기 때문에 확인응답 패킷을 데이터에 편승 시키는게 일반적
- BUT 확인응답을 버퍼에 저장해 두고, 편승할 데이터를 찾지 못하는 경우 그 시간이 더 지연되는 현상 발생

4. 네이글 알고리즘

- 버퍼 Size에 해당하는 데이터가 오면 한 번에 전송
- 해당 크기를 채우지 못하면 추가적인 데이터를 기다리면서 지연될 확률 증가

근데 한 번에 오는거면 content-length가 왜 필요함?
아예 다른 개념이라고 합니다.

TCP와 HTTP 계층에서의 개념들이라 같은 개념이 아님

TCP에서 네이글 알고리즘을 사용하는 것은 택배 트럭이 택배를 모아서 한 번에 출발하는 것

HTTP에서 Content-Length를 파악하는 것은 한 박스의 크기를 파악해서 어디까지가 한 개의 상자인지 구분할 수 있게 하는 것

5. TIME_WAIT 지연과 포트 고갈
   - 2MSL을 기반으로 같은 커넥션이 2분 이내에 또 생성되는 것을 제한
   - 서버가 초당 500개 이상의 트랜잭션을 처리하지 않는 이상 문제 없음

## HTTP 커넥션 관리

### Connection Header

대부분 keep-alive인 경우가 많은데, 일차적인 데이터 송수신이라면 Connection: close라고 설정

Connection header에 들어가는 속성

1. HTTP 헤더 필드

- 이 커넥션에만 해당되는 헤더
- 다음 커넥션에 전달 X

2. 임시 토큰 값

- 커넥션에 대한 비표준 옵션

3. CLOSE

- 작업이 완료되면 커넥션 종료

### 순차적인 트랜잭션 처리에 의한 지연

각 트랜잭션이 새로운 커넥션을 필요로 하면 커넥션을 맺는 과정에서의 지연과 SLOW START 지연 발생

## HTTP 커넥션 성능 향상 방안

### 병렬 커넥션

여러 개의 커넥션을 맺어 여러 HTTP 트랜잭션 병렬 처리

**장점**

- 하나의 커넥션이 대역폭 전체를 사용하지 않기 때문에 남은 대역폭을 사용
- 지연 시간을 겹치게 해서 총 지연 시간 감소

**단점**

- 대역폭이 좁다면 장점 X
- 메모리를 많이 소모

### 지속 커넥션

처리가 완료된 후에도 커넥션 유지

**장점**

- 커넥션 생성 시간 절약
- slow start 회피
- 커넥션 수 감소(메모리 절약)

**단점**

- 관리가 확실하지 않을 경우 불필요한 소모 발생

### Keep-alive 커넥션

HTTP/1.0 - 클라이언트는 Connection:Keep-Alive 헤더를 요청에 포함시켜 보내고, 서버로 부터의 응답에 Connection:Keep-Alive 헤더가 없으면 클라이언트는 서버가 Keep-Alive를 지원하지 않고, 응답 메시지가 전송된뒤 커넥션 종료를 추정

keep-alive를 받았다고 무조건 따를 필요 X

헤더 뒤에는 쉼표로 구분된 옵션이 붙음

1. timeout

- 커넥션 유지 시간 but 이대로 동작한다는 보장 없음

2. max

- 몇 개의 트랜잭션 처리까지 유지할 것인지 but 이대로 동작한다는 보장 없음

### keep-alive 커넥션 제한 및 규칙

1. 기본 유지 x, keep-alive 헤더 필요

2. 엔티티 본문의 길이를 알아야 기존 메시지의 끝과 새로운 메시지의 시작점을 정확히 알 수 있기 때문에 커넥션 유지 가능

3. 프록시나 게이트웨이와 같은 중개자는 connection 헤더 규칙을 지켜야 함

- 메시지를 전달하거나 캐싱 전에 헤더에 명시된 모든 connection 필드와 헤더를 제거
- 하나의 커넥션에서만 connection 헤더를 유지하기 때문에 다음 서버와의 연결에서 해당 헤더를 전송하면 안됨

4. connection 헤더 인식 불가한 프록시 서버와 커넥션 불가

5. 응답 수신 전에 커넥션 종료 시 요청을 다시 보낼 수 있게 준비되어 있어야 함

### 멍청한 프록시

커넥션 헤더 무조건 전달

keep-alive는 한 개의 커넥션에서만 적용 but 이를 이해하지 못하고 제거하지 않은 채로 해당 헤더를 제거하지 않고 그대로 전달

의문점
서버에 keep-alive를 전달해야 연결이 유지되는 것 아닌가?
아님, 해당 '연결 구간' 에서만 의미가 있기 때문에 keep-alive는 각자 연결 구간에 연결을 유지하는 것으로 해석

클라이언트 -> 프록시 -> 서버 라면 클라이언트와 서버가 keep-alive 하는게 아니라 프록시와 서버가 keep-alive를 유지해야 하기 때문에 클라이언트에서 받은 keep-alive를 제거하고 프록시에서 자체적으로 서버와 연결을 유지할 keep-alive를 만들어서 보내야 함

문제 상황

1. 클라이언트가 프록시에 전송한 keep-alive를 제거하거나 재설정하지 않고 서버에 그대로 전송

2. 서버는 프록시가 커넥션 유지를 원한다고 판단하여 keep-alive 규칙에 맞게 통신을 하는 것으로 판단

3. 프록시는 keep-alive가 포함된 응답을 클라이언트로 그대로 전달 => 클라이언트는 프록시와 커넥션이 유지된다고 판단

4. 정작 프록시는 keep-alive가 뭔지 모르기 때문에 응답을 클라이언트에 전달하고 서버와 커넥션이 끊어지길 기다림

5. 이 기다리는 과정에서 클라이언트가 2번째 요청을 보내도 요청을 모두 무시하면서 커넥션이 끊어지길 기다림

6. 타임아웃으로 인해 끊어지지 않는 이상 해결 불가

이를 방지하기 위해 모든 connection 헤더를 제거하는 것

### 프록시 커넥션

모든 헤더를 그대로 전달하는 문제를 해결하기 위한 차선책이 Proxy-Connection 헤더를 사용하는 것 but 모든 상황에서 동작하지는 않음

비표준인 Proxy-Connection 확장 헤더를 프록시에 전달 => 서버는 이를 무시하지만 영리한 프록시는 이를 Connection으로 바꿔 서버에 전송

클라이언트와 서버 사이의 프록시가 1개인 경우에만 동작

중간에 멍청한 프록시가 있다면 문제 재발생

## HTTP/1.1 지속 커넥션

Keep-Alive 지원 x

1.1은 기본으로 지속 커넥션이 활성화
커넥션을 끊으려면 Connection: close 헤더 명시

### 지속커넥션의 제한과 규칙

1. 클라이언트가 커넥션으로 추가 요청을 보내지 않는다면 connection: close 헤더에 포함
2. 커넥션을 유지하려면 모든 메시지가 메시지의 길이 정보를 정확히 가지고 있어야 함
3. 커넥션을 이해하지 못하는 프록시와는 지속 커넥션을 맺으면 안됨
4. 중간에 끊어지는 커넥션 복구가 가능해야 함
5. 중간에 끊어져도 클라이언트는 요청을 다시 보낼 준비가 되어있어야 함

## 파이프라인 커넥션

HTTP/1.1은 지속 커넥션을 이용해 요청 파이프라이닝이 가능

N개의 요청이 응답이 도착하기 전까지 **큐**에 쌓임
첫 번째 요청이 서버에 전달되면 이어서 다음 요청을 전달
네트워크 왕복 시간을 줄여 성능 증가

### 파이프라인 제약

1. 지속 커넥션인지 확인 전까지 파이프라인 금지
2. 응답은 요청 순서와 같게 수신
3. 끊기면 다시 보낼 준비
4. 반복 전송으로 문제가 생길 수 있는 요청(POST)을 파이프라인을 통한 전송 금지 => 에러 발생 시 반복으로 받은 요청 중에 어떤 것이 서버에서 처리 되었는지 알 방법 X

문제점

1. 반드시 순서를 지켜야 하기 때문에 응답 데이터가 준비되는 대로 응답을 보내는 것이 아닌, 요청 순서에 맞게 전송해야 함

```http
① GET /a.html   ← 빠름 (5ms)
② GET /b.css    ← 느림 (200ms)
③ GET /c.js     ← 빠름 (10ms)
```

위 순서의 경우 2번이 끝날 때까지 기다렸다가 3번 응답 전송

2. POST 요청 전송 금지

POST는 요청 횟수에 따라 받는 값이 달라지는 비멱등 요청
같은 POST를 2번 요청하면 받는 값이 달라짐 but 첫 번째 post 요청에 대한 처리가 끝나기 전에 2번째 요청을 시행할 수 있기 때문에 원하는 결과값을 받지 못하는 문제 발생

이를 해결하기 위해 HTTP/2.0에서는 멀티플렉싱을 이용해 병렬적으로 처리하여 순서 상관없이 응답 전송 가능

## 커넥션 끊기

언제, 어떻게 끊을 것인가에 대한 명확한 기준 없음

### 마음대로 끊기

언제든지 TCP 커넥션 끊기 가능

- 커넥션이 유지되는 상황에서 일정 시간 요청이 없고 **유휴상태**에 있으면 끊기 가능
  - 커넥션이 끊어지는 시점에 클라이언트가 전송을 보내면 유휴상태라 커넥션을 끊은건데, 클라이언트는 요청이 잘못됐다고 판단하는 문제 발생

### Content-Length & Truncation

- 오래된 HTTP 서버는 커넥션을 끊을 때 Content-Length 헤더를 생략하거나 잘못 입력하는 경우 있음
- 커넥션이 끊어졌다는 응답을 받은 후 실제 수신한 엔티티 길이와 Content-Length가 일치하는지, 존재하는지 확인해야 함
- 해당 응답을 프록시가 받았다면 캐싱 x

### 커넥션 끊기, 재시도, 멱등

커넥션은 에러가 없어도 마음대로 끊기 가능
앱은 예상치 못한 커넥션 종료에 대응 필요

- 클라이언트가 트랜잭션 도중 커넥션이 끊기면, 재시도 했을 때 문제가 없을 경우 커넥션을 다시 맺고 전송 시도
- 파이프라인에서 서버는 큐에 있는 요청들을 남겨둔 채로 커넥션 종료할 수도 있음
  - 비멱등(post)요청들일 경우 실제로 서버에서 얼만큼 처리됐는지 클라이언트에서 알 수가 없음
  - 비멱등 요청은 하지 말라는 신의 계시
  - 혹시나 비멱등 요청을 다시 보내야 한다면, 이전 요청에 대한 응답을 받을 때까지 기다린 후 전송

## 우아한? 커넥션 끊기

TCP 커넥션은 양쪽에 입력 큐와 출력 큐 보유
TCP 입력 큐나 출력 큐 중 한개만 끊거나 둘 다 끊기 가능

- close()는 TCP 커넥션의 모든 커넥션을 끊음
- shutdown()은 입출력 큐중 하나를 개별적으로 끊기 가능(절반 끊기)

### TCP 종료와 리셋 에러

단순한 HTTP는 전체 끊기만 가능
예상하지 못한 에러를 대비해 절반 끊기를 사용해야 함

- 출력을 끊는 것이 안전
- 입력을 끊을 경우 데이터 전송 도중에 끊길 수 있음. Connection rest by peer라는 에러가 클라이언트로 전송(강제 종료 에러)
- 해당 에러는 심각한 에러로 판별되어 버퍼에 저장된 데이터 전체 삭제

그래서 출력을 끊어라

결론

우아한 커넥션 종료란?

출력을 먼저 끊고 다른 쪽에 있는 출력이 끊기기를 기다리는 것

출력을 양쪽 다 끊으면 커넥션은 위험 없이 온전히 종료

하지만 절반 끊기가 구현되지 않은 곳도 있기 때문에 끊고 난 후에도 입력에 대한 상태 검사가 주기적으로 필요

# 🕔 HTTP 완벽 가이드 5장(웹 서버)🕔

웹 서버는 HTTP 요청을 처리하고 클라이언트에게 응답을 제공하는 역할

웹 서버는 HTTP 프로토콜을 구현, 웹 리소스 관리, 웹 서버 관리 기능 제공

TCP 커넥션 관리에 대한 책임을 OS와 나눔

웹 서버의 2가지 형태

1. 다목적 SW 웹 서버를 설치하여 실행
2. 칩으로 구현된 웹 서버를 내장시켜서 완전한 관리 콘솔로 제공

...?

## 다목적 SW 웹 서버

네트워크에 연결된 표준 컴퓨터 시스템에서 동작

오픈소스 소프트웨어를 사용할 수도 있고, 상용 소프트웨어를 사용할 수도 있음

마이크로소프트, 아파치, NGINX 3가지 웹 서버가 순서대로 가장 널리 상용화

## 임베디드 웹 서버

프린터나 가전제품 등에 내장될 목적으로 만들어진 웹 서버
소비자용 기기를 웹 브라우저 인터페이스로 관리하게 해줌

## 펄 웹 서버

완전한 기능을 갖춘 HTTP 서버는 만들기 어려움
아파치는 50000줄이 넘는 코드로 구성

HTTP/1.1 기능을 갖추려면, 리소스 자원, 가상 호스팅, 접근 제어, 로깅, 설정, 모니터링 등이 필요

최소한의 기능을 하는 HTTP 서버라면 30줄 이하의 펄 코드로도 생성 가능

펄 서버
클라이언트와 프록시 간 상호작용 테스트 툴

HTTP 커넥션을 기다렸다 요청을 받으면 화면에 메시지 출력 => 클라이언트에 답해줄 응답 메시지 기다림

? 다 빼

## 진짜 웹 서버가 하는 일

1. 커넥션 연결 => 클라이언트의 접속 허가 || 접속 비허가
2. 요청 수신 => HTTP 요청 메시지를 네트워크로부터 수신
3. 요청 처리 => 요청 메시지 파싱 및 처리
4. 리소스 접근 => 메시지에서 지정한 리소스 접근
5. 응답 생성 => 올바른 헤더를 포함한 HTTP 응답 메시지 생성
6. 응답 전송 => 응답을 클라이언트로 전송
7. 트랜잭션 로깅 => 로긒파일에 트랜잭션 완료에 대한 기록

### 1. 커넥션 연결

클라이언트가 서버에 TCP 커넥션을 요청하면 서버는 IP 주소를 추출하여 어떤 클라이언트가 커넥션을 맺었는지 확인(클라이언트 호스트 명 식별)

서버는 언제든지 거절하거나 끊기 가능, 호스트 명이 인가되지 않았거나(CORS(?)) 악의적의라고 판단되면 커넥션 종료

❓ CORS 아님 CORS는 브라우저 보안 정책

- HOST 인가 실패 => 서버가 요청을 받을 때 발생, 403 또는 커넥션 종료
- CORS 에러 => 클라이언트가 응답을 받은 후 브라우저가 응답을 차단하고 COSR 에러 출력

ident를 통해 클라이언트 사용자를 알아낼 수 있지만 보안상의 위험으로 현재는 사용하지 않음

```jsx
const app = net.createServer((socket) => {
  // 콜백
});

app.listen(PORT, () => {
  logger.info(`${PORT}번 포트에서 서버 구동 중 *⸜( •ᴗ• )⸝*`);
});
```

- connect()나 브라우저를 통해 서버(localhost:3000)로 요청을 전송
- TCP 3W handshake가 진행
- 연결이 완료되면 socket객체를 생성하고 내부 콜백 호출
- socket이 TCP 연결을 나타내는 객체 === 하나의 커넥션

### 2. 요청 수신

커넥션에 데이터가 도착하면 서버는 데이터를 파싱하여 요청 메시지 구성

```jsx
socket.on("data", (chunk) => {
  ...
});
```

- TCP로 들어온 패킷 데이터 수신

```jsx
buffer += chunk.toString();

if (!buffer.includes("\r\n\r\n")) return;

const [rawHeaders, bodyPart = ""] = buffer.split(DIVIDE.CRLF);

const contentLengthLine = rawHeaders
  .split("\r\n")
  .find((line) => line.startsWith("Content-Length"));

const contentLength = contentLengthLine
  ? parseInt(contentLengthLine.split(":")[1].trim(), 10)
  : 0;

if (bodyPart.length < contentLength) return;

await handleRequest(socket, buffer);
```

- 웹 서버는 요청을 파싱해서 이해하는 것이 가능한 수준의 분량을 확보할 때까지 데이터를 네트워크로부터 읽어와서 메모리에 임시로 저장할 필요가 있음
- 데이터를 받아오는 대로 메모리에 저장하고, Content-Length를 읽어 body가 다 왔는지 확인

**I/O 처리 아키텍쳐**

단일 스레드 웹 서버

- 한 번에 하나씩 요청 처리
- 성능 안좋음

멀티프로세스와 멀티스레드 웹 서버

- 여러 요청을 동시에 처리하기 위해 여러 개의 프로세스 사용
- 빠르지만 너무 많은 메모리나 시스템 리소스 낭비
- 보통 최대 개수 제한함

다중 I/O 서버

- 1개의 스레드가 여러 I/O를 동시에 감시하고 필요한 상황에 처리

다중 멀티스레드 서버

- 멀티스레딩과 다중화를 결합한 것
- 여러 스레드는 모든 커넥션을 감시하며 조금씩 작업을 수행

### 3. 요청 처리

서버는 요청을 받으면 요청으로부터 메서드, 리소스, 헤더, body를 얻어내 처리

```jsx
export const parseRequest = (buffer) => {
  const [rawHeaders, body] = buffer.split(DIVIDE.HTTP_DIVIDE);
  const [requestLine, ...headerLines] = rawHeaders.split(DIVIDE.HEADER_DIVIDE);
  const [method, pathname, protocol] = requestLine.split(" ");

  return {
    method,
    pathname,
    body,
  };
};
```

- GET index.html HTTP/1.1 3가지가 method, pathname, protocol에 담김
- 이 정보를 이용해서 해당 요청에 맞는 함수를 만들어 처리

```jsx
if (method === "POST" && pathname === ROUTES.SIGNUP) {
  return handleSignup(socket, body);
}
if (method === "POST" && pathname === ROUTES.LOGIN) {
  return handleLogin(socket, body);
}

if (method === "POST" && pathname === ROUTES.POST) {
  return handlePostData(socket, body, contentType);
}

if (method === "POST" && pathname === ROUTES.LOGOUT) {
  const cookies = parseCookie(rawHeaders.split(DIVIDE.HEADER_DIVIDE));
  const sessionId = cookies.sessionId;

  return handleLogout(socket, sessionId);
}
if (method === "GET" && pathname === ROUTES.MYPAGE) {
  const cookies = parseCookie(rawHeaders.split(DIVIDE.HEADER_DIVIDE));
  const sessionId = cookies.sessionId;
  return handleMypage(socket, sessionId);
}
```

### 4. 리소스 접근

- URI에 대응하는 알맞은 콘텐츠나 생성기를 웹 서버에서 찾아서 식별하여 제공
- 요청받은 리소스는 서버에 이미 있거나 리소스를 생성하는 함수를 통해 만들어직 동적 콘텐츠일 수 있음

Docroot
리소스 맵핑의 가장 단순한 형태는 요청 URI를 웹 서버의 파일 이름으로 사용하는 것

www.naver.com/index.html 요청이 도착하면 동적 파일 루트 디렉토리(static)에 있는 index.html을 반환

가상 호스팅 docroot를 이용해 여러 웹사이트에서 분리된 한 서버의 리소스에 접근하는 방식도 가능

사용자별로 다른 docroot를 제공할 수도 있음

디렉토리 접근

- 파일이 아닌 디렉토리에 대한 요청을 받을 수도 있음
- 디렉토리에 대한 요청을 받았을 때 처리가 필요
- 보통은 디렉토리 내부에 index.html이 있으면 반환
- 없다면 에러 or 설정한 파일 반환
- 해당 처리가 없다면 아래 이미지와 같이 디렉토리 구조가 열거된 HTML이 반환 => 보안 위험성 증가

<img width="476" height="522" alt="image" src="https://github.com/user-attachments/assets/58cab8db-fde4-4a5a-ae72-6e3820518fd8" />

리소스 맵핑
요청받은 경로명을 실행 가능한 프로그램이 위치한 디렉토리로 맵핑되기도 함

요청 - /index.html
맵핑 - /static/html/index.html

SSI를 설정하면 클라이언트에게 보내기 전에 해당 리소스를 처리하여 동적으로 전송 가능

### 5. 응답 생성

서버가 리소스를 식별하면 서버는 요청 메서드의 동작을 수행한 뒤 응답 메시지 반환

응답 메시지는 응답 상태 코드, 응답 헤더, 응답 본문(있으면)을 포함

```jsx
export const sendHttpResponse = (socket, status, json) => {
  const statusText = STATUS[status] || "OK";

  const body = JSON.stringify(json);
  const response = [
    `HTTP/1.1 ${status} ${statusText}`,
    "Content-Type: application/json; charset=utf-8",
    `Content-Length: ${Buffer.byteLength(body)}`,
    "Connection: close",
    "",
    "",
  ].join("\r\n");

  socket.write(response);
  socket.write(body);
  socket.end();
};
```

```http
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Content-Length: 16
Connection: close

{"message":"OK"}
```

❓본문이 없는 정적 파일 서빙이나 redirect 응답의 경우 Content-Type이나 Content-Length는 미포함(위 코드는 기초 코드)

헤더에는 MIME 타입을 서술하는 Content-Type 헤더가 포함

본문에 담긴 MIME 타입을 결정하는 방법은 여러가지

1. 확장자별 타입 탐색
2. 파일의 내용을 검사해서 패턴에 대한 테이블 탐색(느리지만 확장자가 없을 때 편리)
3. 유형 명시 - 확장자나 내용에 상관 없이 특정 MIME 타입을 가지도록 설정 가능
4. 유형 협상 - 사용자가 사용하기 좋은 형식을 판별할지 설정할 수도 있음

리다이렉션

성공 메시지 대신 리다이렉션 응답을 반환할 수도 있음
서버는 요청을 수행하기 위해 브라우저가 다른 곳으로 이동하도록 리다이렉트 값을 반환하는 것

1. 영구히 리소스가 옮겨졌을 경우

- 리소스의 새 URL이 부여되어 위치가 옮겨지거나 이름이 바뀌었을 수 있음
- 클라이언트에게 새 URL로 요청하라고 리다이렉트
- 301 Moved Permanently 상태 코드
- 임시로 옮겨졌을 경우에는 303이나 307로 리다이렉트만 하고 영구히 바뀐 것은 아니라고 알려주기도 함

2. url 증강

- 상태 정보가 내포된 새 URL로 요청이 필요할 때 리다이렉트
- 트랜잭션 간 상태를 유지하는 유용한 방법

3. 부하 균형

- 서버가 과부하된 요청이면 다른 서버로 리다이렉트 가능

4. 다른 서버

- 친밀한 다른 서버가 있다면 리다이렉트 가능

5. 디렉토리 이름 정규화

- 요청에 빗금이 빠졌다면 경로가 정상적으로 동작하게끔 빗금을 추가한 경로로 리다이렉트

🚨브라우저의 네비게이션은 Location을 통해 리다이렉트되어 받은 html이 있다면 이를 화면에 출력
🚨fetch는 브라우저의 네비게이션 api가 아니라 JS의 네트워크 요청을 수행하는 api

- fetch를 통해 Location이 되면 리다이렉트는 됨
- 하지만 html을 받았다고 해서 그 파일을 출력하지는 않음
- html "값"만 받아옴
- 그렇기 때문에 페이지를 이동시키고 싶을 때 서버에서 Location을 주는 것 보다는 위와 같은 이유로만 사용됨

ex)
회원가입 성공!
Location: login.html 로 리다이렉트 시키고 싶음
fetch를 이용해서 Location을 받으면?
클라이언트는 /login.html을 요청(실제로 url이 이동되지 않음)
login.html "값"을 문자열로 받게됨

그래서 우리는 window.location.href = "/login.html"을 then에다 해주는 것

### 6. 응답 전송

커넥션 상태를 추적해서 만들어진 응답을 해당 커넥션을 통해 전송
socket.write()

### 7. 트랜잭션 로깅

- 트랜잭션이 완료되면 어떻게 수행되었는지 로그를 로그파일에 기록
- 아래는 winston을 이용한 로그 기록

```jsx
import winston from "winston";

// 로그 저장 경로와 포맷 정의
const logger = winston.createLogger({
  level: "info", // 최소 로그 레벨 (info 이상만 기록)
  format: winston.format.combine(
    winston.format.timestamp({ format: "YYYY-MM-DD HH:mm:ss" }),
    winston.format.printf(
      (info) =>
        `${info.timestamp} [${info.level.toUpperCase()}]: ${info.message}`
    )
  ),
  transports: [
    // 콘솔 출력
    new winston.transports.Console(),
    // 파일 저장
    new winston.transports.File({ filename: "logs/error.log", level: "error" }),
    new winston.transports.File({ filename: "logs/combined.log" }),
  ],
});

export default logger;
```

# 🕕 HTTP 완벽 가이드 6장(프록시)🕕

프록시는 중개자
클라이언트와 서버 사이에 위치

## 웹 중개자

클라이언트의 입장에서 트랜잭션을 수행하는 중개자
클라이언트의 입장에서 서버와 대화해주는 프록시와 얘기하는 것
트랜잭션을 완료하는 것이 클라이언트라는 점은 변하지 않음 but 프록시가 제공하는 좋은 기능 이용 가능

클라이언트이자 서버이기 때문에 양쪽 HTTP 규칙 모두를 따라야 함

## 개인, 공유 프록시

공유 프록시

- 대부분의 프록시
- 여러 클라이언트가 함께 사용
- 비용 효율이 높고 관리가 쉬움
- 캐시 프록시는 여러 클라이언트의 공통된 요청에서 이득을 취할 수 있어서 용이

개인 프록시

- 클라이언트에서 직접 실행되는 형태로 꾸준히 사용
- 브라우저 기능 확장 성능 개선을 위해 작은 프록시를 직접 실행

## 프록시 VS 게이트웨이

공통점

- 브라우저와 서버 사이에서 요청과 응답을 주고 받음

차이점

- 프록시: 같은 프로토콜을 사용하는 클라이언트와 서버를 연결
- 게이트웨이: 다른 프로토콜을 사용하는 클라이언트와 서버를 연결
  - 다른 프로토콜로 대화해도 트랜잭션을 완료할 수 있도록 변환기처럼 작동

## 프록시 사용 이유?

프록시는 실용적이고 유용한거라면 뭐든 함
보안 개선, 성능 증가, 비용 절약, 트래픽 감시 후 처리 등

1. 어린이 필터

- 필터링 프록시: 부적절한 사이트 접근 제한

2. 문서 접근 제어

- 접근제어 프록시: 클라이언트별 콘텐츠별 접근 제한 설정

3. 보안 방화벽

- 서버 내부에 들어오거나 나가는 프로토콜의 흐름을 한 지점에서 통제

4. 웹 캐시

- 캐시 프록시: 인기 있는 문서의 사본을 관리 => 요청이 들어오면 빠르게 제공

5. 대리 프록시

- 서버 가속기: 느린 서버를 개선하기 위해 사용

6. 콘텐츠 라우터

- 맞춤형 콘텐츠를 유도하도록 동작

7. 트랜스코더

- 클라이언트에게 전달한 콘텐츠를 자연스럽게 변환하는 것

8. 익명화 프록시

- HTTP 메시지에서 신원 식별 가능한 부분을 적극 제거로 개인정보 보호와 익명성 보장에 기여

## 프록시는 어디?

어떻게 사용할지에 따라 어디든 배치 가능

1. 출구 프록시

- 로컬 네트워크의 출구에 배치
- 로컬 네트워크와 인터넷 사이를 오가는 트래픽 제어용
- 방화벽, 트래픽 성능 개선, 어린이 필터링

2. 입구 프록시

- ISP 접근 지점에 배치
- 캐시 프록시

3. 대리 프록시

- 웹 서버 바로 앞에 배치
- 웹 서버로 향하는 모든 요청 처리
- 필요할 때만 서버에 요청
- 보안 기능 추가, 느린 서버 대신 사용

4. 네트워크 교환 프록시

- 네트워크 사이의 인터넷 피어링 교환 지점에 배치
- ❓피어링: 서로 다른 네트워크가 트래픽을 교환하기 위해 연결되는 것
- 혼잡 완화 및 트래픽 흐름 감시

## 프록시 계층

경우에 따라 프록시 계층이라고 불리는 연쇄 구성 가능
프록시와 프록시를 거쳐 원 서버에 도착하는 것 => 클라이언트로 돌아오는 것도 마찬가지

프록시 계층에서 프록시는 부모와 자식의 관계
서버에서 가까운 쪽 === 부모 프록시 === 인바운드 프록시
클라이언트에서 가깝 === 자식 프록시 === 아웃바운드 프록시

### 컨텐츠 라우팅

프록시 계층은 보통 정적
서버에 가까운 프록시(부모 프록시)로 메시지를 보내는 것이 일반적

하지만 무조건 정적일 필요는 없음
근거에 의해 유동적으로 다른 곳으로 메시지를 보낼 수도 있음

동적으로 보낼 곳을 선택하는 근거의 예시

1. 부하 균형

- 부모 프록시의 작업량 수준에 근거하여 부하를 분산하기 위해 동적 선택

2. 인접성

- 서버의 지역을 담당하는 부모 선택 가능

3. 프로토콜/타입 라우팅

- URI에 근거하여 다른 프록시나 서버로 라우팅

4. 유료 서비스 가입자 트래픽에 대한 라우팅

- 그들의 URI는 대형 캐시나 압축 엔진으로 라우팅

### 트래픽 처리

HTTP 트래픽이 프록시로 향하는 길을 찾아내는 방법?

1. 클라이언트 수정

- 요청을 의도적으로 프록시로 보내도록 설정

2. 네트워크 수정

- 클라이언트 모르게 네트워크 인프라를 가로채서 트래픽을 프록시로 가도록 설정

3. DNS 수정

- 웹 서버의 DN과 IP를 대리 프록시가 직접 사용
- 요청이 서버 대신 대리 프록시로 이동

4. 서버 수정

- 리다이렉트 헤더를 이용해 프록시로 요청하도록 설정

프록시 사용 설정 방법?

1. 수동 설정

2. 브라우저 기본 설정

3. 프록시 자동 설정

4. WPAD 프록시 발견

요런게 있구나 정도만 알고 20장 가서 더 빡빡하게 공부하기

## 프록시 요청 특징

프록시 요청의 URI와 서버 URI

서버로 요청을 보낼 때 => 부분 URI
GET /index.html HTTP/1.1

프록시로 요청을 보낼 때 => 완전한 URI
GET www.naver.com/index.html HTTP/1.1

왜?
프록시가 요청을 받고 서버랑 커넥션을 맺어야 하는데, 어떤 서버인지 알아야 하기 때문 but 부분 URI를 보내는게 대부분(프록시를 고려하지 않고 구축된 서버가 많기 때문)이라 문제가 많이 발생함

가상 호스팅에서도 같은 문제 발생

왜?
요청은 부분 URI로 가는데 어느 웹 사이트의 접근할지에 대한 호스트 명을 모르기 때문

프록시는 완전한 URI와 부분 URI를 다 다룰 수 있어야 함

1. 완전한 URI => 어느 서버인지 알 수 있기 때문에 바로 처리
2. 부분 URI + HOST 헤더 => 가상으로 호스팅 되는 웹 서버에 정보가 HOST 헤더에 담겨있기 때문에 해당하는 서버로 처리
3. 부분 URI

- 인터셉트 프록시는 서버로 가는 트래픽을 가로채기 때문에 서버로 보내는 부분 URI를 얻어서 처리
- 대리 프록시는 해당 URI가 서버를 대신하는 프록시이기 때문에 바로 처리
- 아니면 HOST 헤더를 명시해달라고 요청을 보내야 함

전송 중에 URI를 변경하거나 자동확장 기능을 이용해 시도를 해보기도 함

### URI 분석

프록시가 없을 때

- www.이나 .com을 붙여서 확장
- DNS서버에서 확장한 IP 주소를 찾으면 반환
- IP 주소에 대해 성공할 때까지 접속 시도
- 성공 시 커넥션
- 트랜잭션

명시적 프록시 URI 분석

- DNS를 사용해 프록시 서버 탐색
- 프록시 서버 IP 주소 반환
- 프록시와 커넥션 시도
- HTTP 요청 전송
- 명시적 프록시가 있는 경우 호스트 명 자동 확장 X
- 프록시는 요청에 부분 URI를 받음

## 메시지 추적

프록시의 성능이 좋기 때문에 요청이 프록시 여러개를 지나가는 일이 비일비재

프록시를 넘나드는 메시지의 흐름을 추적하고 문제점을 찾아내는 것도 중요해짐

이를 지원하는 것이 Via 헤더

### via 헤더

프록시나 게이트웨이를 지날 때마다 해당 정보를 나열

쉼표로 구성된 경유지 목록

```bash
Via: 1.1 proxy-62.irenes-isp.net, 1.0 cache.joes-hardware.com
```

- 2개의 프록시를 거쳐온 http 요청
- 해당 내용을 악의적인 목적으로 이용할 수도 있음
- 그럴 때는 내부에 값을 합쳐서 가명으로 교체하기도 함

### TRACE

커넥션을 통해 이동될 때마다 어떤 프록시를 지나가고, 어떻게 각 프록시가 요청을 수정하는지 관찰/추적할 수 있는 메서드

프록시 흐름을 디버깅하는데 매우 유용

TRACE 요청이 서버에 도착하면 서버는 전체 요청 메시지를 HTTP 응답 메시지의 본문에 포함시켜 송신자에게 그대로 전송(이 요청이 온게 맞는지 확인하라는 용도)

클라이언트는 이를 보고 서버가 요청 받은 메시지를 검사하고, 어떤 프록시를 지나왔는지 확인 가능

## 프록시 인증

리소스에 대한 유효한 접근 권한 자격을 프록시에 제출하지 않는 한 콘텐츠에 대한 요청을 차단하는 프록시 인증 매커니즘을 정의

제출한 자격이 유효하다면 연쇄를 따라 요청을 통과시켜 서버로 전송

자세한 설명은 12장
